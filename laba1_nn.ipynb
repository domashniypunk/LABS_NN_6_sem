{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h1e7hMHKetl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy.random import uniform\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aq3R2NgRKoY_"
      },
      "outputs": [],
      "source": [
        "def shuffle(list1, list2):\n",
        "    temp = list(zip(list1, list2))\n",
        "    np.random.shuffle(temp)\n",
        "    res1, res2 = zip(*temp)\n",
        "    res1, res2 = list(res1), list(res2)\n",
        "    return res1, res2\n",
        "\n",
        "def train_speed_dont_decrease_func(epoch_now, decrease_count, train_speed):\n",
        "    return decrease_count, train_speed\n",
        "\n",
        "def train_speed_decrease_func(epoch_now, decrease_count, train_speed):\n",
        "    if (epoch_now % 30 == 0):\n",
        "             train_speed *= 0.93\n",
        "             decrease_count += 1\n",
        "    return decrease_count, train_speed\n",
        "\n",
        "\n",
        "def sigm(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "coeff = 0.1\n",
        "\n",
        "def der_sigm(x):\n",
        "    return sigm(x) * (1 - sigm(x))  \n",
        "\n",
        "def relu(x):\n",
        "  try:\n",
        "    a = iter(x)\n",
        "    array = []\n",
        "    for i in x:\n",
        "      if i >= 0:\n",
        "        array.append(coeff * i)\n",
        "      else:\n",
        "        array.append(0)\n",
        "    return np.array(array)\n",
        "  except:\n",
        "    return coeff * x\n",
        "\n",
        "def der_relu(x):\n",
        "  try:\n",
        "    array = []\n",
        "    for i in x:\n",
        "      if i >= 0:\n",
        "        array.append(coeff)\n",
        "      else:\n",
        "        array.append(0)\n",
        "    return np.array(array)\n",
        "  except:\n",
        "    return coeff\n",
        "    \n",
        "\n",
        "class Net:\n",
        "    def __init__(self, inputs, neurons_array, activations = None, deriviatives = None, weight_border = 0.5, normalize_weights = True):\n",
        "        if activations != None: \n",
        "            self.acts = activations\n",
        "            self.ders = deriviatives\n",
        "        else:\n",
        "            self.acts = [sigm for i in range(len(neurons_array))]\n",
        "            self.ders = [der_sigm for i in range(len(neurons_array))]\n",
        "\n",
        "        self.G = [[0 for n in range(neurons_array[i])] for i in range(len(neurons_array))]\n",
        "        \n",
        "        self.train_speed_decrease_func = train_speed_dont_decrease_func\n",
        "        self.round_training_predict = True\n",
        "\n",
        "        inputs += 1\n",
        "\n",
        "        self.weights = [[[uniform(-weight_border, weight_border) for k in range(neurons_array[i - 1] + 1 if i > 0 else inputs)] for j in range(neurons_array[i])] for i in range( len(neurons_array))]\n",
        "        \n",
        "        if normalize_weights:\n",
        "            for i in range(len(neurons_array)):\n",
        "                inputs = neurons_array[i - 1] + 1 if i > 0 else inputs\n",
        "                b = 0.7 * (neurons_array[i] ** (1 / inputs))\n",
        "                for j in range(len(self.weights[i])):\n",
        "                    sum = np.sum(self.weights[i][j])\n",
        "                    for k in range(len(self.weights[i][j])):\n",
        "                        self.weights[i][j][k] = b * self.weights[i][j][k] / sum\n",
        "\n",
        "        self.fields = [[0 for j in range(neurons_array[i])] for i in range(len(neurons_array))]\n",
        "        self.J = []\n",
        "        self.H = []\n",
        "        self.train_size_epoch = 1\n",
        "\n",
        "        self._l = len(self.weights) - 1\n",
        "    \n",
        "    def _normalize_weights(self, inputs_count):\n",
        "        for i in range(len(self.weights)):\n",
        "                inputs = len(self.weights[i - 1]) + 1 if i > 0 else inputs_count\n",
        "                b = 0.7 * (len(self.weights[i]) ** (1 / inputs))\n",
        "                for j in range(len(self.weights[i])):\n",
        "                    sum = np.sum(self.weights[i][j])\n",
        "                    for k in range(len(self.weights[i][j])):\n",
        "                        self.weights[i][j][k] = b * self.weights[i][j][k] / sum\n",
        "        \n",
        "    def predict(self, signals : any):\n",
        "        signals = np.append(signals.copy(), 1)\n",
        "\n",
        "        for i in range(len(self.weights[0])):\n",
        "            self.fields[0][i] = np.dot(self.weights[0][i], signals)\n",
        "\n",
        "        for i in range(1, len(self.weights)):\n",
        "            for j in range(len(self.weights[i])):\n",
        "                self.fields[i][j] = np.dot(self.weights[i][j], np.append(self.acts[i - 1](np.array(self.fields[i - 1].copy())), 1))\n",
        "\n",
        "        arr = np.array(self.fields[self._l].copy())\n",
        "        return self.acts[self._l](arr)\n",
        "    \n",
        "    def train(self, x_train, y_train, train_speed, max_epochs,  max_error = 0.1):\n",
        "        errs_history = []\n",
        "        hitrate_history = []\n",
        "\n",
        "        decrease_count = 0\n",
        "\n",
        "        x_train = x_train.copy()\n",
        "        y_train = y_train.copy()\n",
        "\n",
        "        if not isinstance(y_train, np.ndarray):\n",
        "            y_train = np.array(y_train)\n",
        "\n",
        "        for epoch in range(max_epochs):\n",
        "\n",
        "            print(f'epoch {epoch + 1} has started', end='')\n",
        "\n",
        "            x, y = None, None\n",
        "\n",
        "            x_train, y_train = shuffle(x_train, y_train)\n",
        "\n",
        "            if self.train_size_epoch == 1:\n",
        "                x, y = x_train, y_train\n",
        "            else:\n",
        "                x, a, y, b = train_test_split(x_train, y_train, train_size=self.train_size_epoch, random_state=42)\n",
        "\n",
        "            x, y = shuffle(x, y)\n",
        "\n",
        "            errs = 0\n",
        "\n",
        "            for i_x in range(len(x)):\n",
        "                y_pr = self.predict(x[i_x])\n",
        "\n",
        "                error = y_pr - y[i_x]\n",
        "\n",
        "                errs += np.square(error).mean()\n",
        "\n",
        "                self._back_prop(error, x, i_x, train_speed)\n",
        "            \n",
        "            # errs = errs / len(x) if len(x) > 1 else errs * len(self.weights[self._l])\n",
        "            errs /= len(x)\n",
        "            errs_history.append(errs)\n",
        "            \n",
        "            print(f', error = {errs}')\n",
        "\n",
        "            if max_error != None and errs <= max_error:\n",
        "                print(f'fitted by error')\n",
        "                return\n",
        "\n",
        "            decrease_count, train_speed = self.train_speed_decrease_func(epoch, decrease_count, train_speed)\n",
        "\n",
        "        print('ended by epochs')\n",
        "\n",
        "    def _get_signals(self, x, i, i_x):\n",
        "        signals = self.acts[i - 1](np.array(self.fields[i - 1].copy())) if i > 0 else x[i_x].copy()\n",
        "        signals = np.append(signals, 1)\n",
        "        return signals\n",
        "    \n",
        "    def _back_prop(self, error, x, i_x, train_speed):\n",
        "\n",
        "        for i in range(len(self.weights[self._l])):\n",
        "            g = self.ders[self._l](self.fields[self._l][i]) * error[i]\n",
        "            self.G[self._l][i] = g\n",
        "            signals = self._get_signals(x, self._l, i_x)\n",
        "            for j in range(len(self.weights[self._l][i])):\n",
        "                self.weights[self._l][i][j] -= train_speed * self.G[self._l][i] * signals[j]\n",
        "        \n",
        "        for i in range(self._l - 1, -1, -1):\n",
        "            signals = self._get_signals(x, i, i_x)\n",
        "            for j in range(len(self.weights[i])):\n",
        "                weighted_sum = 0\n",
        "                for k in range(len(self.weights[i + 1])):\n",
        "                    weighted_sum += self.G[i + 1][k] * self.weights[i + 1][k][j]\n",
        "                g = self.ders[i](self.fields[i][j]) * weighted_sum \n",
        "\n",
        "                self.G[i][j] = g\n",
        "\n",
        "                for k in range(len(self.weights[i][j])):\n",
        "                    self.weights[i][j][k] -= train_speed * self.G[i][j] * signals[k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmexcW58KqPc"
      },
      "outputs": [],
      "source": [
        "(X_trn, y_trn), (X_tst, y_tst) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9YcceqgKsas"
      },
      "outputs": [],
      "source": [
        "def make_samples(x, y, trn_show, n_samples):\n",
        "  dictionary = {}\n",
        "  for i in range(10):\n",
        "    dictionary[i] = 0\n",
        "  # x, y = shuffle(x, y)\n",
        "  y_train = []\n",
        "  x_train = []\n",
        "  show = []\n",
        "  for i in range(len(x)):\n",
        "    number = y[i]\n",
        "    if dictionary[number] < n_samples:\n",
        "      x_train.append(x[i])\n",
        "      y_train.append(y[i])\n",
        "      show.append(trn_show[i])\n",
        "      dictionary[number] += 1\n",
        "    if np.sum(list(dictionary.values())) == n_samples * 10:\n",
        "      break\n",
        "  # print(dictionary)\n",
        "  return np.array(x_train), np.array(y_train), show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THyUdyj-Kuu5"
      },
      "outputs": [],
      "source": [
        "X_train = X_trn.reshape([-1, 28 * 28]) / 255.0\n",
        "X_test = X_tst.reshape([-1, 28 * 28]) / 255.0\n",
        "\n",
        "y_train = y_trn.copy()\n",
        "y_test = y_tst.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mtys-7CDK1Oq",
        "outputId": "85005773-8b7e-4a2e-b1e7-e15e865926be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train, X_train_show = make_samples(X_train, y_train, X_trn, 40)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNWIaBNzK-1F"
      },
      "outputs": [],
      "source": [
        "inputs = 28 * 28\n",
        "neurons = [128, 32, 1]\n",
        "acts = [sigm, sigm, relu]\n",
        "ders = [der_sigm, der_sigm, der_relu]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBQAfeVaLAYl"
      },
      "outputs": [],
      "source": [
        "model = Net(inputs, neurons, activations=acts, deriviatives=ders)\n",
        "model.train_size_epoch = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt_tILHlL4Og",
        "outputId": "bfbfffac-b868-4708-cf8f-eb44cd73f61c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 has started, error = 8.301958924855319\n",
            "epoch 2 has started, error = 4.807637134365201\n",
            "epoch 3 has started, error = 3.544028381110672\n",
            "epoch 4 has started, error = 3.1583208253603\n",
            "epoch 5 has started, error = 2.838472656593547\n",
            "epoch 6 has started, error = 2.295031290463058\n",
            "epoch 7 has started, error = 1.85892250497766\n",
            "epoch 8 has started, error = 1.593174743247502\n",
            "epoch 9 has started, error = 1.3036913820046945\n",
            "epoch 10 has started, error = 0.9774737931715606\n",
            "epoch 11 has started, error = 0.6548803820713686\n",
            "epoch 12 has started, error = 0.5212990218432035\n",
            "epoch 13 has started, error = 0.40360794415327256\n",
            "epoch 14 has started, error = 0.34697116952217705\n",
            "epoch 15 has started, error = 0.25815251818275053\n",
            "epoch 16 has started, error = 0.19336130494113501\n",
            "epoch 17 has started, error = 0.15639103858239933\n",
            "epoch 18 has started, error = 0.13870952273634982\n",
            "epoch 19 has started, error = 0.10993001858728339\n",
            "epoch 20 has started, error = 0.11333752971051168\n",
            "epoch 21 has started, error = 0.08837873255396962\n",
            "epoch 22 has started, error = 0.07275823277413322\n",
            "epoch 23 has started, error = 0.060753296293449936\n",
            "epoch 24 has started, error = 0.05053627985701958\n",
            "epoch 25 has started, error = 0.043934205467115676\n",
            "epoch 26 has started, error = 0.03498712114043799\n",
            "epoch 27 has started, error = 0.035082194848787315\n",
            "epoch 28 has started, error = 0.03074352644734287\n",
            "epoch 29 has started, error = 0.026587519035295756\n",
            "epoch 30 has started, error = 0.023024485392156412\n",
            "ended by epochs\n"
          ]
        }
      ],
      "source": [
        "model.train(X_train, y_train, 0.1, 30, max_error = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z95ZSu1rRwiY",
        "outputId": "1ad242e7-c308-41fb-ffd9-9934b4009e39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hitrate is 0.5465. Mean squared error is [2.54127612]\n"
          ]
        }
      ],
      "source": [
        "acc = 0\n",
        "mse = 0\n",
        "for i in range(len(X_test)):\n",
        "  pred = model.predict(X_test[i])\n",
        "  if round(pred[0]) == y_test[i]:\n",
        "    acc += 1\n",
        "  mse += (pred - y_test[i]) ** 2\n",
        "acc /= len(X_test)\n",
        "mse /= len(X_test)\n",
        "print('Hitrate is {0}. Mean squared error is {1}'.format(acc, mse))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}